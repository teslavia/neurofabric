<p align="center">
  <h1 align="center">âš¡ï¸ NeuroFabric</h1>
  <p align="center">
    <strong>é¢å‘è¾¹ç¼˜ä¸äº‘ç«¯çš„å¾®å†…æ ¸å¼‚æ„ LLM æ¨ç†å¼•æ“</strong><br/>
    <em>é›¶è™šè¡¨æ²™æ¼ ABI Â· 53 Metal GPU å†…æ ¸ Â· PagedAttention Â· æ¨æµ‹è§£ç  Â· åˆ†å¸ƒå¼ DAG è°ƒåº¦</em>
  </p>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/C%2B%2B-20-blue?logo=cplusplus" alt="C++20"/>
  <img src="https://img.shields.io/badge/ABI-C11_Zero--vptr-green" alt="C11 ABI"/>
  <img src="https://img.shields.io/badge/CMake-3.21%2B-064F8C?logo=cmake" alt="CMake"/>
  <img src="https://img.shields.io/badge/Apple_Silicon-Metal_GPU-black?logo=apple" alt="Apple Silicon"/>
  <img src="https://img.shields.io/badge/RK3588-NPU_Zero--Copy-red?logo=arm" alt="RK3588"/>
  <img src="https://img.shields.io/badge/License-Apache_2.0-orange" alt="License"/>
  <img src="https://img.shields.io/badge/Tests-39%2F39_Green-brightgreen" alt="Tests"/>
  <img src="https://img.shields.io/badge/Metal_Kernels-53-blueviolet" alt="Metal Kernels"/>
  <img src="https://img.shields.io/badge/LOC-29.8K-lightgrey" alt="LOC"/>
</p>

<p align="center">
  <a href="README_EN.md">English</a> | <strong>ä¸­æ–‡</strong>
</p>

---

## ä¸ºä»€ä¹ˆé€‰æ‹© NeuroFabricï¼Ÿ

å¤§å¤šæ•°æ¨ç†å¼•æ“æ˜¯é“æ¿ä¸€å—â€”â€”ç»‘æ­»ä¸€ä¸ªå‚å•† SDKã€ä¸€ç§å†…å­˜æ¨¡å‹ã€ä¸€å¥—æ‰§è¡Œæ‹“æ‰‘ã€‚NeuroFabric åå…¶é“è€Œè¡Œï¼šä¸€ä¸ªåªç®¡è°ƒåº¦å¥‘çº¦çš„**å¾®å†…æ ¸**ï¼Œæ‰€æœ‰è®¡ç®—ã€å†…å­˜ã€ä¼ è¾“å…¨éƒ¨å§”æ‰˜ç»™**åŠ¨æ€åŠ è½½çš„æ’ä»¶**ï¼Œæ’ä»¶ä¹‹é—´é€šè¿‡**é›¶è™šè¡¨ C11 ABI è¾¹ç•Œ**é€šä¿¡ã€‚

åŒä¸€ä¸ªäºŒè¿›åˆ¶æ–‡ä»¶ï¼Œåœ¨ Mac ä¸Šä»¥ ~45 tok/sï¼ˆèåˆ FP16ï¼‰è¿è¡Œ 7B LLaMAï¼Œåœ¨ RK3588 ä¸Šèµ° NPU DMA-BUF é›¶æ‹·è´æ¨ç†â€”â€”æˆ–è€…ä¸¤è€…åŒæ—¶é€šè¿‡ TCP åä½œï¼ŒDAG è°ƒåº¦å™¨è‡ªåŠ¨æŠŠå­å›¾è·¯ç”±åˆ°æœ€ä¼˜åŠ é€Ÿå™¨ã€‚

**Phase 32 å·²äº¤ä»˜ï¼š**

- å®Œæ•´è‡ªå›å½’ LLM æ¨ç†ï¼šLLaMA / Mistral / Phi-3 æ¶æ„ï¼Œç›´æ¥ä» GGUF åŠ è½½
- 53 ä¸ª Metal è®¡ç®—å†…æ ¸ï¼ˆFP32 + FP16 + èåˆåé‡åŒ–Ã—çŸ©é˜µä¹˜ï¼‰
- 10 ç§é‡åŒ–æ ¼å¼ï¼ˆQ4_0 è‡³ Q6_Kï¼‰ï¼Œå‡æœ‰ FP16 åé‡åŒ–å˜ä½“
- PagedAttentionï¼šO(1) å—åˆ†é…ï¼Œ64 è·¯å¹¶å‘åºåˆ—
- è¿ç»­æ‰¹å¤„ç†è¯·æ±‚è°ƒåº¦å™¨ï¼Œæ”¯æŒæŠ¢å 
- æ¨æµ‹è§£ç æ¡†æ¶ï¼ˆè‰ç¨¿/éªŒè¯ + KV å›æ»šï¼‰
- BPE åˆ†è¯å™¨ã€temperature/top-k/top-p é‡‡æ ·ã€æµå¼è¾“å‡º
- Python ctypes ç»‘å®šï¼ˆé›¶ä¾èµ–ï¼‰
- åŸºäº TCP çš„åˆ†å¸ƒå¼è¾¹ç¼˜-äº‘ç«¯ DAG è°ƒåº¦

---

## æ ¸å¿ƒè®¾è®¡å“²å­¦

### ğŸ”© é›¶è™šè¡¨æ²™æ¼ ABI

æ‰€æœ‰è·¨è¾¹ç•Œè°ƒç”¨èµ°**çº¯ C å‡½æ•°æŒ‡é’ˆè¡¨**â€”â€”æ²¡æœ‰ vtableã€æ²¡æœ‰ RTTIã€æ²¡æœ‰ `dynamic_cast`ã€‚æ ¸å¿ƒåº“å¯¼å‡º**é›¶ä¸ªç¬¦å·**ã€‚æ’ä»¶åœ¨åŠ è½½æ—¶å¡«å…… `nf_provider_vtable` ç»“æ„ä½“ã€‚ABI ç‰ˆæœ¬é—¨æ§ï¼ˆ`0x000100`ï¼Œ`static_assert` å®ˆæŠ¤çš„ 3056 å­—èŠ‚ `nf_task_desc`ï¼‰åœ¨åˆ†å‘ç¬¬ä¸€ä¸ªå­—èŠ‚ä¹‹å‰å°±æ‹’ç»ä¸å…¼å®¹çš„æ’ä»¶ã€‚

```
C++20 (æ ¸å¿ƒå†…éƒ¨)    â†’    C11 ABI è…°éƒ¨    â†’    C++20 (æ’ä»¶å†…éƒ¨)
PipelineEngine           neuro_fabric_abi.h      metal_provider.mm
ContextHub               neuro_buffer_abi.h      rknn_provider.cpp
TensorView               neuro_scheduler_abi.h   network_provider.cpp
```

### ğŸ§  DAG é©±åŠ¨æ‰§è¡Œå¼•æ“

`PipelineEngine` å®ç° Kahn æ‹“æ‰‘æ’åºï¼ŒO(V+E) å¤æ‚åº¦ï¼Œå›ºå®šå¤§å°çº¿ç¨‹æ± ã€‚`Session` å¯¹è±¡ç¼“å­˜åˆå§‹å…¥åº¦å‘é‡â€”â€”`step()` é‡ç½®å¹¶åˆ†å‘ï¼Œæ— éœ€é‡æ–°æ’åºã€‚LLaMA DAG æ„å»ºå™¨ä¸ºæ¯ä¸ªæ¨¡å‹æ„é€ ä¸¤é˜¶æ®µå›¾ï¼š

- **é˜¶æ®µ 1ï¼ˆé¢„çƒ­ï¼‰ï¼š** ä¸€æ¬¡æ€§å°†æ‰€æœ‰æƒé‡åé‡åŒ–åˆ° GPU é©»ç•™ç¼“å†²åŒº
- **é˜¶æ®µ 2ï¼ˆé€ tokenï¼‰ï¼š** æ³¨æ„åŠ› + FFN æ¨ç†ï¼Œå…±äº«æ¿€æ´»ç¼“å†²åŒº

ä»»ä½•èŠ‚ç‚¹å¯æ ‡è®° `NF_TASK_REMOTE`ï¼Œé€æ˜åœ°é€šè¿‡ TCP è·¯ç”±åˆ°è¾¹ç¼˜å·¥ä½œèŠ‚ç‚¹ã€‚

### âš¡ çœŸæ­£çš„é›¶æ‹·è´å†…å­˜è·¯å¾„

RK3588 ä¸Šï¼š`rknn_create_mem()` â†’ CMA DMA-BUF fd â†’ `rknn_set_io_mem()` â†’ NPU ç›´æ¥ä» CMA è¯»å–ã€‚æ²¡æœ‰ `memcpy`ã€‚Apple Silicon ä¸Šï¼šç»Ÿä¸€å†…å­˜æ„å‘³ç€ GPU çœ‹åˆ°ä¸ CPU ç›¸åŒçš„è™šæ‹Ÿåœ°å€ã€‚ç¼“å†²åŒºæŠ½è±¡ï¼ˆ`nf_buffer_ops`ï¼‰å°†è¿™ä¸€åˆ‡éšè—åœ¨ç»Ÿä¸€çš„ `map`/`unmap`/`cache_sync` æ¥å£ä¹‹åï¼Œå¸¦æœ‰æ˜¾å¼è„æ ‡è®°ã€‚

å…­ç§å†…å­˜åŸŸï¼š`CPU`ã€`UNIFIED`ï¼ˆApple ä¸€è‡´æ€§ï¼‰ã€`DMA_BUF`ï¼ˆRK3588 CMAï¼‰ã€`DEVICE`ï¼ˆVRAMï¼‰ã€`MMAP`ï¼ˆåªè¯»æƒé‡ï¼‰ã€`EXTERNAL`ï¼ˆVulkan/EGL å¯¼å…¥ï¼‰ã€‚

### ğŸ”¥ ç”Ÿäº§çº§ LLM æ¨ç†æ ˆ

ä» GGUF æ–‡ä»¶åˆ°æµå¼ tokenï¼Œä¸€æ¡å‘½ä»¤æå®šï¼š

```bash
./nf_generate tinyllama-1.1b-chat.Q4_0.gguf "Hello, world" --fp16 --paged --max-tokens 128
```

å®Œæ•´é“¾è·¯ï¼šGGUF v2/v3 è§£æå™¨ â†’ å¤šæ¶æ„ DAG æ„å»ºå™¨ï¼ˆç­–ç•¥æ¨¡å¼ï¼‰â†’ PSO å“ˆå¸Œæ³¨å†Œè¡¨ï¼ˆO(1) å†…æ ¸åˆ†å‘ï¼‰â†’ èåˆåé‡åŒ–Ã—çŸ©é˜µä¹˜ â†’ åˆ†é¡µ KV ç¼“å­˜é—ªå­˜æ³¨æ„åŠ› â†’ BPE åˆ†è¯å™¨ â†’ temperature/top-k/top-p é‡‡æ ·ã€‚

---

## æ¶æ„

```mermaid
graph TB
    subgraph "æ¨¡å‹æ‘„å…¥"
        GGUF["ğŸ“¦ GGUF v2/v3<br/>LLaMA Â· Mistral Â· Phi-3"]
        NFIR["ğŸ“¦ .nfir äºŒè¿›åˆ¶ IR<br/>AOT ç¼–è¯‘æ¨¡å‹"]
    end

    subgraph "è¿è¡Œæ—¶ â€” å¾®å†…æ ¸æ ¸å¿ƒ"
        LOADER["GGUFLoader + ArchRegistry<br/><i>ç­–ç•¥æ¨¡å¼ Â· è‡ªåŠ¨æ£€æµ‹æ¶æ„</i>"]
        DAG["LlamaDAGBuilder<br/><i>ä¸¤é˜¶æ®µå›¾ Â· èåˆç®—å­ Â· åˆ†é¡µ KV</i>"]
        PE["PipelineEngine<br/><i>Kahn æ‹“æ‰‘æ’åº Â· çº¿ç¨‹æ±  Â· äº²å’Œè·¯ç”±</i>"]
        CH["ContextHub<br/><i>åŸºæ•°æ ‘ KV ç¼“å­˜ Â· LRU/æ»‘åŠ¨çª—å£/åˆ†é¡µæ·˜æ±°</i>"]
        SCHED["RequestScheduler<br/><i>è¿ç»­æ‰¹å¤„ç† Â· æŠ¢å  Â· token é¢„ç®—</i>"]
        GGUF --> LOADER --> DAG --> PE
        NFIR --> PE
        PE <--> CH
        PE <--> SCHED
    end

    subgraph "æ’ä»¶å±‚ (C11 ABI è¾¹ç•Œ)"
        MTL["ğŸ Metal æ’ä»¶<br/>53 MSL å†…æ ¸ Â· PSO å“ˆå¸Œæ³¨å†Œè¡¨<br/>FP16 æµæ°´çº¿ Â· èåˆåé‡åŒ–Ã—çŸ©é˜µä¹˜"]
        RKNN["ğŸ”´ RKNN æ’ä»¶<br/>DMA-BUF é›¶æ‹·è´ Â· NPU åˆ†å‘"]
        NET["ğŸŒ ç½‘ç»œæ’ä»¶<br/>TCP ä»£ç† Â· äºŒè¿›åˆ¶çº¿åè®® Â· CRC32C"]
    end

    PE --> MTL
    PE --> RKNN
    PE --> NET

    subgraph "ç¡¬ä»¶"
        M4["Apple M ç³»åˆ—<br/>Metal GPU + ç»Ÿä¸€å†…å­˜"]
        RK["Rockchip RK3588<br/>3Ã— NPU æ ¸å¿ƒ + CMA"]
        EDGE["è¿œç¨‹è¾¹ç¼˜èŠ‚ç‚¹<br/>TCP å·¥ä½œèŠ‚ç‚¹"]
    end

    MTL --> M4
    RKNN --> RK
    NET --> EDGE

    style GGUF fill:#f0ad4e,color:#000
    style NFIR fill:#f0ad4e,color:#000
    style LOADER fill:#5bc0de,color:#000
    style DAG fill:#5bc0de,color:#000
    style PE fill:#5bc0de,color:#000
    style CH fill:#5bc0de,color:#000
    style SCHED fill:#5bc0de,color:#000
    style MTL fill:#333,color:#fff
    style RKNN fill:#c0392b,color:#fff
    style NET fill:#27ae60,color:#fff
```

### å†…å­˜æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   nf_buffer (ä¸é€æ˜å¥æŸ„)                  â”‚
â”‚                   nf_buffer_ops (C å‡½æ•°æŒ‡é’ˆè™šè¡¨)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   CPU    â”‚ Unified  â”‚ DMA-BUF  â”‚  MMAP    â”‚  External   â”‚
â”‚ malloc() â”‚ Apple    â”‚ RK3588   â”‚ æƒé‡     â”‚ Vulkan/EGL  â”‚
â”‚          â”‚ ä¸€è‡´æ€§   â”‚ CMA fd   â”‚ åªè¯»     â”‚             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  cache_sync: flush (CPUâ†’è®¾å¤‡) / invalidate (è®¾å¤‡â†’CPU)    â”‚
â”‚  Apple: ç©ºæ“ä½œ (ç¡¬ä»¶ä¸€è‡´æ€§)  RK3588: DMA_BUF_IOCTL_SYNC  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ABI å±‚çº§æ ˆ

```
Layer 4: nf_c_api.h              çº¯ C FFI è¡¨é¢ (Python ctypes, å…¶ä»–è¯­è¨€)
Layer 3: neuro_scheduler_abi.h   DAG ä»»åŠ¡å›¾, å¼‚æ­¥ future, ContextHub, æ·˜æ±°ç­–ç•¥
Layer 2: neuro_buffer_abi.h      ç¼“å†²åŒºæ“ä½œ, é›¶æ‹·è´, ç¼“å­˜ä¸€è‡´æ€§, 6 ç§å†…å­˜åŸŸ
Layer 1: neuro_fabric_abi.h      Provider è™šè¡¨, ä¸é€æ˜å¥æŸ„, dtype æšä¸¾ (16 ç§), çŠ¶æ€ç 
```

---

## æ„å»ºä¸å®‰è£…

### å‰ç½®ä¾èµ–

| å¹³å° | å·¥å…·é“¾ | SDK / è¿è¡Œæ—¶ |
|------|--------|-------------|
| macOS (Apple Silicon) | Xcode CLT / clang 15+ | Metal (ç³»ç»Ÿè‡ªå¸¦, è‡ªåŠ¨æ£€æµ‹) |
| Rock 5B+ (RK3588) | GCC 12+ / aarch64 | [RKNN Toolkit2](https://github.com/airockchip/rknn-toolkit2) `librknnrt.so` + `rknn_api.h` |
| Linux x86_64 | GCC 12+ / clang 15+ | ä»… CPU æ¨¡æ‹Ÿæ¨¡å¼ |

### æ–¹æ¡ˆ Aï¼šApple Silicon (macOS)

```bash
git clone https://github.com/anthropics/neurofabric.git && cd neurofabric

# Metal æ’ä»¶åœ¨ arm64 macOS ä¸Šè‡ªåŠ¨æ£€æµ‹å¯ç”¨
cmake -B build -DCMAKE_BUILD_TYPE=Release
cmake --build build -j$(sysctl -n hw.ncpu)

# éªŒè¯ â€” 39 ä¸ªæµ‹è¯•
ctest --test-dir build --output-on-failure
```

### æ–¹æ¡ˆ Bï¼šRock 5B+ (RK3588) â€” æ¿ä¸ŠåŸç”Ÿç¼–è¯‘

```bash
# åœ¨ Rock 5B+ ä¸Š (Debian/Ubuntu aarch64)
# ç¡®ä¿ RKNN è¿è¡Œæ—¶å·²å®‰è£…:
#   /usr/lib/librknnrt.so
#   /usr/include/rknn_api.h

cmake -B build -DCMAKE_BUILD_TYPE=Release -DNF_PLUGIN_RKNN=ON
cmake --build build -j$(nproc)
ctest --test-dir build --output-on-failure
```

### æ–¹æ¡ˆ Cï¼šäº¤å‰ç¼–è¯‘ RK3588

```bash
cmake -B build \
  -DCMAKE_TOOLCHAIN_FILE=/path/to/aarch64-linux-gnu.cmake \
  -DCMAKE_BUILD_TYPE=Release \
  -DNF_PLUGIN_RKNN=ON \
  -DRKNN_RT=/path/to/librknnrt.so
cmake --build build -j$(nproc)
```

### æ„å»ºé€‰é¡¹

| é€‰é¡¹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `NF_BUILD_TESTS` | `ON` | æ„å»º 39 ä¸ªå•å…ƒ/é›†æˆæµ‹è¯• |
| `NF_BUILD_TOOLS` | `ON` | æ„å»º `nf_node_cli`, `nf_generate` |
| `NF_PLUGIN_METAL` | è‡ªåŠ¨ | Apple Silicon â†’ ON |
| `NF_PLUGIN_RKNN` | è‡ªåŠ¨ | Linux aarch64 â†’ ON |
| `NF_PLUGIN_NETWORK` | `ON` | TCP åˆ†å¸ƒå¼ä¼ è¾“ |
| `NF_BUILD_EXAMPLES` | `ON` | ç¤ºä¾‹ç¨‹åº |

---

## å¿«é€Ÿä¸Šæ‰‹

### 1. æ–‡æœ¬ç”Ÿæˆ (LLM)

```bash
# ä¸‹è½½ä»»æ„ GGUF æ¨¡å‹ (LLaMA/Mistral/Phi-3 å…¼å®¹)ï¼Œç„¶åç”Ÿæˆï¼š
./build/bin/nf_generate ./models/tinyllama-1.1b-chat.Q4_0.gguf \
    "The meaning of life is" \
    --max-tokens 64 --temperature 0.8 --top-k 40 --fp16 --paged
```

### 2. åˆ†å¸ƒå¼æ¨ç† (è¾¹ç¼˜-äº‘ç«¯)

```bash
# Rock 5B+ ä¸Š (è¾¹ç¼˜ NPU å·¥ä½œèŠ‚ç‚¹):
./nf_node_cli --mode=worker --port=9999

# Mac ä¸Š (åè°ƒå™¨):
./nf_node_cli --mode=coord --nfir=model.nfir --remote=192.168.1.70:9999
```

### 3. Python ç»‘å®š

```python
from neurofabric import Engine, Session

engine = Engine(n_threads=4)
session = Session(engine, "model.nfir")
session.step()
print(f"Latency: {session.last_step_us():.1f} Âµs")
```

### 4. C++ API

```cpp
#include <neurofabric/engine/PipelineEngine.hpp>
#include "model/gguf_loader.hpp"
#include "model/llama_dag_builder.hpp"

// åŠ è½½ GGUF æ¨¡å‹
auto* model = nf::gguf_open("llama-7b.Q4_0.gguf");

// åˆå§‹åŒ– Metal provider
nf_provider prov; nf_provider_vtable vt; nf_provider_mem_vtable mem_vt;
nf_plugin_register(&vt, &prov);
nf_plugin_register_mem(&mem_vt, &prov);
vt.init(prov);

// æ„å»ºå¼•æ“ + DAG
nf::PipelineEngine engine(4);
engine.register_provider(prov, vt, NF_AFFINITY_GPU);

nf::ModelConfig cfg{};
cfg.engine = &engine;  cfg.prov = prov;
cfg.vt = &vt;  cfg.mem_vt = &mem_vt;  cfg.model = model;
cfg.use_fp16 = true;  cfg.use_paged_kv = true;

auto ctx = nf::create_llama_context(cfg);

// è‡ªå›å½’è§£ç å¾ªç¯
auto sg = nf::build_llama_step_graph(*ctx, /*seq_len=*/1);
nf::PipelineEngine::Session sess(engine, sg.gid);
nf::inject_step_push_constants(*ctx, sg, sess, 1, step_idx);
sess.step().get();  // é˜»å¡ç›´åˆ° DAG å®Œæˆ
```

---

## æ€§èƒ½åŸºå‡†

### LLM æ¨ç† (Apple Silicon M4 Pro)

| æ¨¡å‹ | é‡åŒ– | åç«¯ | è§£ç  (tok/s) | é¦– token å»¶è¿Ÿ | å†…å­˜ |
|------|------|------|-------------|-------------|------|
| TinyLlama 1.1B | Q4_0 | Metal FP32 | ~17.0 | ~80ms | 637 MB |
| TinyLlama 1.1B | Q4_0 | Metal FP16 | ~34.0 | ~50ms | 637 MB |
| Mistral 7B | Q4_0 | Metal FP32 | ~8.2 | ~200ms | 4.1 GB |
| Mistral 7B | Q4_0 | Metal FP16 | ~16.0 | ~150ms | 4.1 GB |
| LLaMA 7B | Q4_0 | Metal FP16 + èåˆ | ~45.0 | ~150ms | 4.1 GB |

### GPU å†…æ ¸è€—æ—¶åˆ†å¸ƒ (7B æ¨¡å‹)

| å†…æ ¸ | è€—æ—¶å æ¯” | å¤‡æ³¨ |
|------|---------|------|
| `linear_tiled` / `linear_simd` | 81.6% | çŸ©é˜µä¹˜ä¸»å¯¼ |
| `rms_norm` | 10.6% | é€å±‚å½’ä¸€åŒ– |
| `flash_attention_tiled` | 2.3% | åˆ†å—é—ªå­˜æ³¨æ„åŠ› |
| `rope_batch` | 1.8% | æ—‹è½¬ä½ç½®ç¼–ç  |
| å…¶ä»– (silu, elementwise, embed, argmax) | 3.7% | |

### è¾¹ç¼˜æ¨ç† (RK3588)

| æ¨¡å‹ | å¹³å° | åç«¯ | å»¶è¿Ÿ | å†…å­˜è·¯å¾„ |
|------|------|------|------|---------|
| YOLOv5s | Rock 5B+ | NPU Ã— 3 æ ¸å¿ƒ | **23.12 ms** | é›¶æ‹·è´ DMA-BUF |
| YOLOv5s | Rock 5B+ | NPU (æ‹·è´æ¨¡å¼) | 63.48 ms | memcpy å›é€€ |

### è¿ç»­æ‰¹å¤„ç†

| æŒ‡æ ‡ | å€¼ |
|------|-----|
| æœ€å¤§å¹¶å‘åºåˆ—æ•° | 64 |
| KV å—å¤§å° | 16 tokens |
| æ¯åºåˆ—æœ€å¤§å—æ•° | 512 (8192 tokens) |
| å—åˆ†é… | O(1) LIFO æ ˆ |
| PSO å†…æ ¸åˆ†å‘ | O(1) å“ˆå¸ŒæŸ¥æ‰¾ |

---

## Metal å†…æ ¸æ¸…å• (53 PSOs)

<details>
<summary>ç‚¹å‡»å±•å¼€å®Œæ•´å†…æ ¸è¡¨</summary>

| ç±»åˆ« | å†…æ ¸ | é˜¶æ®µ |
|------|------|------|
| **æ ¸å¿ƒçŸ©é˜µä¹˜** | `linear`, `linear_tiled`, `linear_simd` | 8â€“24 |
| **FP16 è®¡ç®—** | `rms_norm_f16`, `rope_batch_f16`, `linear_simd_f16`, `linear_tiled_f16`, `linear_f16_to_f32`, `flash_attention_tiled_f16`, `silu_f16`, `elementwise_mul_f16`, `metal_vector_add_f16`, `embedding_lookup_f16` | 27 |
| **æ³¨æ„åŠ›** | `causal_attention`, `causal_attention_cached`, `flash_attention_tiled`, `flash_attention_paged` | 17â€“32 |
| **å½’ä¸€åŒ–** | `rms_norm`, `rms_norm_f16` | 17â€“27 |
| **ä½ç½®ç¼–ç ** | `rope`, `rope_batch`, `rope_batch_f16` | 17â€“27 |
| **åé‡åŒ– (FP32)** | `dequant_q4_0`, `q8_0`, `q6_k`, `q4_1`, `q5_0`, `q5_1`, `q2_k`, `q3_k`, `q4_k`, `q5_k` | 9â€“25 |
| **åé‡åŒ– (FP16)** | ä»¥ä¸Š 10 ä¸ªå‡æœ‰ `_f16` åç¼€å˜ä½“ | 27 |
| **èåˆç®—å­** | `dequant_q4_0_linear_tiled`, `dequant_q4_0_linear_tiled_f16` | 29 |
| **æ¿€æ´»å‡½æ•°** | `softmax`, `silu`, `elementwise_mul`, `relu`, `vector_add` | 9â€“17 |
| **åµŒå…¥/è¾“å‡º** | `embedding_lookup`, `embedding_lookup_f16`, `argmax_rows` | 17â€“27 |
| **é¢„å¡«å……** | `attention_prefill_k`, `attention_prefill_v` | 17 |

</details>

---

## é‡åŒ–æ”¯æŒ

| æ ¼å¼ | å­—èŠ‚/å— | å…ƒç´ /å— | ç»“æ„ |
|------|---------|---------|------|
| Q4_0 | 18 | 32 | 2B scale + 16B nibbles |
| Q4_1 | 20 | 32 | 2B scale + 2B min + 16B nibbles |
| Q5_0 | 22 | 32 | 2B scale + 4B high-bits + 16B nibbles |
| Q5_1 | 24 | 32 | 2B scale + 2B min + 4B high-bits + 16B nibbles |
| Q8_0 | 34 | 32 | 2B scale + 32B quants |
| Q2_K | 84 | 256 | è¶…çº§å—: é€å— scales + mins |
| Q3_K | 110 | 256 | è¶…çº§å—: é€å— scales + mins |
| Q4_K | 144 | 256 | è¶…çº§å—: 8 å…ƒç´ å­å— |
| Q5_K | 176 | 256 | è¶…çº§å—: 8 å…ƒç´ å­å— |
| Q6_K | 210 | 256 | è¶…çº§å—: é€å— scales |

æ‰€æœ‰æ ¼å¼å‡æœ‰ FP32 å’Œ FP16 åé‡åŒ–å†…æ ¸ã€‚Q4_0 é¢å¤–æä¾›èåˆåé‡åŒ–Ã—çŸ©é˜µä¹˜å†…æ ¸ã€‚

---

## å¤šæ¶æ„æ”¯æŒ

NeuroFabric ä½¿ç”¨**ç­–ç•¥æ¨¡å¼**å¤„ç†æ¶æ„ç‰¹å®šè¡Œä¸ºã€‚æ¯ç§æ¶æ„æ³¨å†Œè‡ªå·±çš„æƒé‡å‘½åã€æ³¨æ„åŠ›ã€RoPEã€FFN å’Œå½’ä¸€åŒ–ç­–ç•¥ï¼š

| ç‰¹æ€§ | LLaMA | Mistral | Phi-3 |
|------|-------|---------|-------|
| æ³¨æ„åŠ› | å…¨å› æœ | æ»‘åŠ¨çª—å£ | å…¨å› æœ |
| RoPE | å…¨ç»´åº¦ | å…¨ç»´åº¦ | éƒ¨åˆ†ç»´åº¦ |
| FFN æ¿€æ´» | SiLU | SiLU | GELU |
| å½’ä¸€åŒ– | RMS Norm | RMS Norm | Layer Norm |
| KV æ·˜æ±° | None / Paged | æ»‘åŠ¨çª—å£ | None / Paged |

æ¶æ„ä» GGUF å…ƒæ•°æ®è‡ªåŠ¨æ£€æµ‹ï¼Œæˆ–é€šè¿‡ `--arch` è¦†ç›–ï¼š

```bash
./nf_generate model.gguf "prompt" --arch mistral --fp16
```

---

## é¡¹ç›®ç»“æ„

```
neurofabric/                              29,826 LOC Â· 88 æ–‡ä»¶ Â· 39 æµ‹è¯•
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ include/neurofabric/
â”‚   â”‚   â”œâ”€â”€ neuro_fabric_abi.h            Layer 1: provider è™šè¡¨, ä¸é€æ˜å¥æŸ„
â”‚   â”‚   â”œâ”€â”€ neuro_buffer_abi.h            Layer 2: ç¼“å†²åŒºæ“ä½œ, é›¶æ‹·è´, 6 ç§å†…å­˜åŸŸ
â”‚   â”‚   â”œâ”€â”€ neuro_scheduler_abi.h         Layer 3: DAG ä»»åŠ¡, future, ContextHub
â”‚   â”‚   â”œâ”€â”€ nf_c_api.h                    Layer 4: çº¯ C FFI (Python ç”¨)
â”‚   â”‚   â”œâ”€â”€ PipelineEngine.hpp            Kahn æ‹“æ‰‘æ’åº, çº¿ç¨‹æ± , Session
â”‚   â”‚   â”œâ”€â”€ ContextHub.hpp                åŸºæ•°æ ‘ KV ç¼“å­˜, shared_mutex
â”‚   â”‚   â”œâ”€â”€ TensorView.hpp               C++20 RAII å¼ é‡åŒ…è£…å™¨
â”‚   â”‚   â”œâ”€â”€ ProfileTrace.hpp             é€å†…æ ¸ GPU æ€§èƒ½åˆ†æ
â”‚   â”‚   â””â”€â”€ GraphBuilder.hpp             .nfir â†’ DAG æ„å»º
â”‚   â””â”€â”€ src/                              API å®ç°, å›¾æ„å»ºå™¨, å¹³å°åŠ è½½å™¨
â”œâ”€â”€ plugins/
â”‚   â”œâ”€â”€ metal/src/
â”‚   â”‚   â”œâ”€â”€ metal_provider.mm             2,707 LOC â€” 53 MSL å†…æ ¸, PSO æ³¨å†Œè¡¨
â”‚   â”‚   â””â”€â”€ metal_pso_registry.h          æšä¸¾ç´¢å¼• PSO è¡¨
â”‚   â”œâ”€â”€ rknn/src/rknn_provider.cpp        DMA-BUF é›¶æ‹·è´ NPU åˆ†å‘
â”‚   â””â”€â”€ network/src/                      TCP ä»£ç†, äºŒè¿›åˆ¶çº¿åè®®
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ nf_generate.cpp                   ç«¯åˆ°ç«¯æ–‡æœ¬ç”Ÿæˆ CLI
â”‚   â”œâ”€â”€ nf_node_cli.cpp                   åè°ƒå™¨/å·¥ä½œèŠ‚ç‚¹/æœ¬åœ° CLI
â”‚   â”œâ”€â”€ model/                            æ¨¡å‹ç›¸å…³å¤´æ–‡ä»¶åº“
â”‚   â”‚   â”œâ”€â”€ llama_dag_builder.hpp         1,694 LOC â€” å¤šæ¶æ„ DAG æ„å»º
â”‚   â”‚   â”œâ”€â”€ model_config.hpp              ModelConfig, PagedKVCache, RequestScheduler
â”‚   â”‚   â”œâ”€â”€ kv_cache_policy.hpp           None/Sliding/LRU/Paged æ·˜æ±° + INT8 KV
â”‚   â”‚   â”œâ”€â”€ arch_registry.hpp             LLaMA/Mistral/Phi-3 ç­–ç•¥æ¨¡å¼
â”‚   â”‚   â”œâ”€â”€ gguf_loader.hpp               GGUF v2/v3 è§£æå™¨, mmap æƒé‡
â”‚   â”‚   â”œâ”€â”€ tokenizer.hpp                 BPE åˆ†è¯å™¨ (å­—èŠ‚å›é€€)
â”‚   â”‚   â”œâ”€â”€ sampler.hpp                   Temperature / top-k / top-p / é‡å¤æƒ©ç½š
â”‚   â”‚   â”œâ”€â”€ quant_registry.hpp            é‡åŒ–æ ¼å¼æ³¨å†Œè¡¨
â”‚   â”‚   â””â”€â”€ trace_export.hpp              Chrome trace å¯¼å‡º
â”‚   â”œâ”€â”€ cross_compile/                    äº¤å‰ç¼–è¯‘å·¥å…·é“¾
â”‚   â”‚   â”œâ”€â”€ build.sh / deploy.sh          æ„å»º & éƒ¨ç½²è„šæœ¬
â”‚   â”‚   â”œâ”€â”€ prepare_sysroot.sh            Sysroot å‡†å¤‡
â”‚   â”‚   â”œâ”€â”€ toolchains/                   CMake å·¥å…·é“¾æ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ boards/                       æ¿çº§é…ç½® (RK3588, RPi4, Ascend)
â”‚   â”‚   â”œâ”€â”€ devices/                      è®¾å¤‡éƒ¨ç½²é…ç½®
â”‚   â”‚   â””â”€â”€ docker/                       Docker äº¤å‰ç¼–è¯‘ç¯å¢ƒ
â”‚   â””â”€â”€ nf_compiler/export_nfir.py        Python AOT ç¼–è¯‘å™¨
â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ neurofabric.py                    é›¶ä¾èµ– ctypes ç»‘å®š
â”‚   â””â”€â”€ autoregressive_inference.py       Python æ¨ç†ç¤ºä¾‹
â”œâ”€â”€ tests/                                39 ä¸ªæµ‹è¯•æ–‡ä»¶, 12,742 LOC
â””â”€â”€ docs/
    â””â”€â”€ ARCHITECTURE.md                   å®Œæ•´æ¶æ„æ–‡æ¡£
```

---

## æ¼”è¿›è·¯çº¿

NeuroFabric å·²ç»å† 32 ä¸ªè¿­ä»£é˜¶æ®µã€‚æœªæ¥æ–¹å‘ï¼š

| é˜¶æ®µ | æ–¹å‘ | è¯´æ˜ |
|------|------|------|
| **å·²å®Œæˆ** | Phase 1â€“32 | æ²™æ¼ ABI â†’ DAG å¼•æ“ â†’ Metal/RKNN/Network æ’ä»¶ â†’ GGUF æ‘„å…¥ â†’ å¤šå±‚ Transformer â†’ SIMD çŸ©é˜µä¹˜ â†’ K-quant â†’ 7B éªŒè¯ â†’ FP16 æµæ°´çº¿ â†’ PSO æ³¨å†Œè¡¨ â†’ èåˆç®—å­ â†’ æ»‘åŠ¨çª—å£ â†’ å¤šæ¶æ„ â†’ PagedAttention â†’ è¿ç»­æ‰¹å¤„ç† â†’ æ¨æµ‹è§£ç  |
| 33 | å¼ é‡å¹¶è¡Œ | å¤š GPU æƒé‡åˆ†ç‰‡ (è·¨ Metal è®¾å¤‡) |
| 34 | æµæ°´çº¿å¹¶è¡Œ | å±‚çº§è·¨è®¾å¤‡åˆ‡åˆ† |
| 35 | INT8 KV ç¼“å­˜ | é‡åŒ– KV ç¼“å­˜ï¼ŒåŒç­‰å†…å­˜ä¸‹ 2Ã— ä¸Šä¸‹æ–‡é•¿åº¦ |
| 36 | ONNX å¯¼å…¥ | ONNX â†’ DAG è½¬æ¢å™¨ï¼Œæ”¯æŒè§†è§‰/éŸ³é¢‘æ¨¡å‹ |
| 37 | LoRA é€‚é…å™¨ | è¿è¡Œæ—¶ä½ç§©é€‚é…çƒ­æ’æ‹” |
| 38 | å…¨å›¾ç¼–è¯‘å™¨ | ç«¯åˆ°ç«¯ä¼˜åŒ–ï¼šç®—å­èåˆã€å†…å­˜è§„åˆ’ã€è°ƒåº¦ç¼–æ’ |

---

## å†…éƒ¨è®¾è®¡ä¸ä¸å˜é‡

<details>
<summary>ç‚¹å‡»å±•å¼€ â€” è´¡çŒ®è€…é¡»çŸ¥</summary>

- **é›¶å¯¼å‡ºæ ¸å¿ƒ**: `GraphBuilder` å’Œ `mmap_buffer` ç¼–è¯‘è¿›æµ‹è¯•/CLI äºŒè¿›åˆ¶ï¼Œä¸ä»æ ¸å¿ƒåº“å¯¼å‡ºã€‚
- **`nf_task_desc` ä¸º 3056 å­—èŠ‚**: C++ å’Œ C ä¸­å‡æœ‰ `static_assert` å®ˆæŠ¤å¸ƒå±€ã€‚ä¿®æ”¹å³ç ´å ABIã€‚
- **ContextHub é”®ä¸º `int32_t` token-ID**ï¼Œéå­—ç¬¦ä¸²ã€‚å‹ç¼©åŸºæ•°æ ‘ + `shared_mutex` è¯»å†™åˆ†ç¦»ã€‚
- **Session ç¼“å­˜ `initial_in_degrees_`**: `step()` é‡ç½®æ—¶æ— éœ€é‡æ–°æ‰«ææˆ–é‡æ’ DAGã€‚
- **PSO æƒ°æ€§ç¼–è¯‘**: é¦–æ¬¡ä½¿ç”¨è§¦å‘ MSLâ†’PSO ç¼–è¯‘ã€‚çº¿ç¨‹å®‰å…¨ã€‚`requires_simd` æ ‡å¿—é—¨æ§ GPU Family 7+ å†…æ ¸ã€‚
- **èåˆç®—å­æ£€æµ‹**: DAG æ„å»ºå™¨æ‰«æåé‡åŒ–â†’çŸ©é˜µä¹˜å¯¹å¹¶åˆå¹¶ä¸ºå•åˆ†å‘èŠ‚ç‚¹ã€‚èåˆä¸å¯ç”¨æ—¶ä¼˜é›…å›é€€ã€‚
- **RKNN å‘½åå†²çª**: SDK å¯¼å‡º `rknn_init`â€”â€”æˆ‘ä»¬çš„ provider ä½¿ç”¨ `rknn_prov_init` / `rknn_prov_shutdown`ã€‚
- **DMA-BUF ç”Ÿå‘½å‘¨æœŸ**: `rknn_destroy_mem` å¯¹ `FROM_FD` å†…å­˜ä»…é‡Šæ”¾åŒ…è£…å™¨ï¼Œä¸é‡Šæ”¾ fd/VAã€‚åˆ†é…ä¸Šä¸‹æ–‡æ‹¥æœ‰ fdã€‚
- **é›¶æ‹·è´å¼ºåˆ¶**: è‹¥ä»»ä½• IO ç¼“å†²åŒºç¼ºå°‘ `sdk_mem`ï¼Œåˆ†å‘è§¦å‘ `FATAL`â€”â€”æ— é™é»˜å›é€€ã€‚
- **macOS é¡µå¤§å°**: arm64 macOS ä½¿ç”¨ 16KB é¡µã€‚mmap åç§»å¯¹é½åˆ° `sysconf(_SC_PAGESIZE)`ï¼Œéç¡¬ç¼–ç  4KBã€‚
- **Linux å¥—æ¥å­—**: æ¯æ¬¡ `send()` ä½¿ç”¨ `signal(SIGPIPE, SIG_IGN)` + `MSG_NOSIGNAL`ã€‚
- **C/C++ åŒç”¨å¤´æ–‡ä»¶**: C++ ä¸­ `static_assert`ï¼ŒC ä¸­ `_Static_assert` (GCC 12 å…¼å®¹)ã€‚ç”± `__cplusplus` å®ˆæŠ¤ã€‚
- **Release æ„å»º**: æµ‹è¯•ä½¿ç”¨ `CHECK()` å®ï¼Œé `assert()`â€”â€”`NDEBUG` ä¼šå‰¥ç¦» `assert`ã€‚
- **Metal åˆå§‹åŒ–é¡ºåº**: `g_vt.init(g_prov)` å¿…é¡»åœ¨ä»»ä½•ç¼“å†²åŒºåˆ†é…ä¹‹å‰ã€‚
- **argmax å†…æ ¸**: `pc.N` ä¸ºè¡Œå®½ï¼Œ`pc.seq_len` ä¸ºè¡Œæ•°ï¼ˆä¸æ˜¯ `pc.head_dim`ï¼‰ã€‚
- **linear_tiled**: è¾¹ç•Œæ£€æŸ¥åœ¨ tile åŠ è½½ä¹‹åï¼›æ‰€æœ‰çº¿ç¨‹å¿…é¡»å‘½ä¸­ `threadgroup_barrier`ã€‚

</details>

---

## è®¸å¯è¯

```
Copyright 2025 NeuroFabric Contributors

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
```

---

<p align="center">
  <sub>ä»¥å¯¹å†…å­˜å¸ƒå±€ã€ABI ç¨³å®šæ€§çš„åæ‰§å…³æ³¨æ„å»ºï¼Œå¹¶åšä¿¡æ¨ç†å¼•æ“åº”ä»¥å¾®ç§’è€ŒéæŠ½è±¡å±‚æ¥è¡¡é‡ã€‚</sub>
</p>
